{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c21da7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leoar\\AppData\\Local\\Temp\\ipykernel_7568\\2832268761.py:2: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This is used to increase the notebook's width to fill the screen, allowing for better plot visualization\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5b99c4",
   "metadata": {},
   "source": [
    "# Path to Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecf4a24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "425024\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>source</th>\n",
       "      <th>class</th>\n",
       "      <th>country</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>partition</th>\n",
       "      <th>slice_selection</th>\n",
       "      <th>x_min</th>\n",
       "      <th>y_min</th>\n",
       "      <th>x_max</th>\n",
       "      <th>y_max</th>\n",
       "      <th>verified_finding</th>\n",
       "      <th>view</th>\n",
       "      <th>modality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NCP_96_1328_0032.png</td>\n",
       "      <td>NCP_96</td>\n",
       "      <td>CNCB</td>\n",
       "      <td>COVID-19</td>\n",
       "      <td>China</td>\n",
       "      <td>M</td>\n",
       "      <td>74.0</td>\n",
       "      <td>train</td>\n",
       "      <td>Expert</td>\n",
       "      <td>9</td>\n",
       "      <td>94</td>\n",
       "      <td>512</td>\n",
       "      <td>405</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Axial</td>\n",
       "      <td>CT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NCP_96_1328_0035.png</td>\n",
       "      <td>NCP_96</td>\n",
       "      <td>CNCB</td>\n",
       "      <td>COVID-19</td>\n",
       "      <td>China</td>\n",
       "      <td>M</td>\n",
       "      <td>74.0</td>\n",
       "      <td>train</td>\n",
       "      <td>Expert</td>\n",
       "      <td>10</td>\n",
       "      <td>106</td>\n",
       "      <td>512</td>\n",
       "      <td>405</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Axial</td>\n",
       "      <td>CT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NCP_96_1328_0036.png</td>\n",
       "      <td>NCP_96</td>\n",
       "      <td>CNCB</td>\n",
       "      <td>COVID-19</td>\n",
       "      <td>China</td>\n",
       "      <td>M</td>\n",
       "      <td>74.0</td>\n",
       "      <td>train</td>\n",
       "      <td>Expert</td>\n",
       "      <td>10</td>\n",
       "      <td>105</td>\n",
       "      <td>512</td>\n",
       "      <td>406</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Axial</td>\n",
       "      <td>CT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NCP_96_1328_0037.png</td>\n",
       "      <td>NCP_96</td>\n",
       "      <td>CNCB</td>\n",
       "      <td>COVID-19</td>\n",
       "      <td>China</td>\n",
       "      <td>M</td>\n",
       "      <td>74.0</td>\n",
       "      <td>train</td>\n",
       "      <td>Expert</td>\n",
       "      <td>11</td>\n",
       "      <td>104</td>\n",
       "      <td>512</td>\n",
       "      <td>406</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Axial</td>\n",
       "      <td>CT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCP_96_1328_0038.png</td>\n",
       "      <td>NCP_96</td>\n",
       "      <td>CNCB</td>\n",
       "      <td>COVID-19</td>\n",
       "      <td>China</td>\n",
       "      <td>M</td>\n",
       "      <td>74.0</td>\n",
       "      <td>train</td>\n",
       "      <td>Expert</td>\n",
       "      <td>11</td>\n",
       "      <td>103</td>\n",
       "      <td>512</td>\n",
       "      <td>406</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Axial</td>\n",
       "      <td>CT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               filename patient_id source     class country sex   age  \\\n",
       "0  NCP_96_1328_0032.png     NCP_96   CNCB  COVID-19   China   M  74.0   \n",
       "1  NCP_96_1328_0035.png     NCP_96   CNCB  COVID-19   China   M  74.0   \n",
       "2  NCP_96_1328_0036.png     NCP_96   CNCB  COVID-19   China   M  74.0   \n",
       "3  NCP_96_1328_0037.png     NCP_96   CNCB  COVID-19   China   M  74.0   \n",
       "4  NCP_96_1328_0038.png     NCP_96   CNCB  COVID-19   China   M  74.0   \n",
       "\n",
       "  partition slice_selection  x_min  y_min  x_max  y_max verified_finding  \\\n",
       "0     train          Expert      9     94    512    405              Yes   \n",
       "1     train          Expert     10    106    512    405              Yes   \n",
       "2     train          Expert     10    105    512    406              Yes   \n",
       "3     train          Expert     11    104    512    406              Yes   \n",
       "4     train          Expert     11    103    512    406              Yes   \n",
       "\n",
       "    view modality  \n",
       "0  Axial       CT  \n",
       "1  Axial       CT  \n",
       "2  Axial       CT  \n",
       "3  Axial       CT  \n",
       "4  Axial       CT  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Relative path to dataset\n",
    "data_dir = os.path.join( \"C:\\\\Datasets\", \"COVID19\", \"Tomografia\", \"COVIDx CT-3A\" )\n",
    "assert os.path.exists( data_dir ), \"Unable to find the relative path to COVIDx CT-3A, please check data_dir...\"\n",
    "\n",
    "export_dir = os.path.join( \"C:\\\\Datasets\", \"COVID19\", \"CT\", \"classification\" )\n",
    "if not os.path.exists(export_dir):\n",
    "    os.makedirs(export_dir)\n",
    "\n",
    "# Path to metadata csv\n",
    "csv_path = os.path.join( data_dir, \"new_split_metadata.csv\" )\n",
    "\n",
    "# Reads metadata as dataframe, \"age\" column is treated as str since \"N/A\" can't be int\n",
    "samples_df = pd.read_csv(csv_path, sep = \";\", na_filter = False, dtype={\"age\": str})\n",
    "print( len(samples_df) )\n",
    "samples_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016e3015",
   "metadata": {},
   "source": [
    "# Resize Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddf20500",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_img( exp_path, src_img ):\n",
    "    # Saves the resized image (creates saving directory if needed)\n",
    "    exp_dir = os.path.dirname(exp_path)\n",
    "    if not os.path.exists(exp_dir):\n",
    "        os.makedirs(exp_dir)\n",
    "    cv2.imwrite(exp_path, src_img)\n",
    "    return\n",
    "\n",
    "def copy_file( src_path, dst_path ):\n",
    "    # Copies a file\n",
    "    dst_dir = os.path.dirname(dst_path)\n",
    "    if not os.path.exists(dst_dir):\n",
    "        os.makedirs(dst_dir)\n",
    "    shutil.copy2(src_path, dst_path)\n",
    "    return\n",
    "\n",
    "def resize_samples( df, import_dir, sub_dir, export_dir, dataset, sizes, seed = 42 ):\n",
    "    \n",
    "    # Sets a seed for reprodutibility\n",
    "    np.random.seed( seed )\n",
    "    \n",
    "    # Filters inputed df to select only rows from the current source\n",
    "    source_df = df[ df[\"source\"] == dataset ].copy(deep = True)\n",
    "    source_df.reset_index(drop = True, inplace = True)\n",
    "    \n",
    "    # Defines the interpolation method used for each sample. Used Interpolations are: \n",
    "    # 0 = INTER_NEAREST, 1 = INTER_LINEAR, 2 = INTER_CUBIC, 3 = INTER_AREA, 4 = INTER_LANCZOS4\n",
    "    # The same image will be resized with the same interpolation regardless of the output shape\n",
    "    source_df[\"interpolation\"] = source_df.apply(lambda row: np.random.randint(0, 5), axis = 1)\n",
    "    \n",
    "    # Converts to dict for faster iteration through rows\n",
    "    df_dict = source_df.to_dict( \"records\" )\n",
    "    for row in tqdm(df_dict):\n",
    "        \n",
    "        # Paths to import the original image and export the resized ones\n",
    "        import_path = os.path.join( import_dir, sub_dir, row[\"filename\"] )\n",
    "        ex_csv_path = os.path.join( row[\"source\"], row[\"partition\"], row[\"filename\"] )\n",
    "        \n",
    "        # Lists all resized paths for the current file\n",
    "        export_paths = []\n",
    "        for size in sizes:\n",
    "            if size == \"original\":\n",
    "                export_paths.append( os.path.join( export_dir, \"original\", ex_csv_path ) )\n",
    "            else:\n",
    "                export_paths.append( os.path.join( export_dir, f\"{size}x{size}\", ex_csv_path ) )\n",
    "                \n",
    "        # Skips current file if all resized images exist\n",
    "        if all([os.path.exists(p) for p in export_paths]):\n",
    "            continue\n",
    "        \n",
    "        # Loads original image\n",
    "        src_img = cv2.imread( import_path, -1 )\n",
    "        \n",
    "        for size, export_path in zip(sizes, export_paths):\n",
    "            if os.path.exists(export_path):\n",
    "                continue\n",
    "                \n",
    "            if size == \"original\":\n",
    "                copy_file( import_path, export_path )\n",
    "            \n",
    "            else:\n",
    "                # Resizes using a randomly chosen interpolation method and saves the resulting image\n",
    "                dst_img = cv2.resize( src_img, (size, size), interpolation = row[\"interpolation\"] )\n",
    "                save_img( export_path, dst_img )\n",
    "    \n",
    "    # Saving dataset with updated paths\n",
    "    source_df[\"path\"] = source_df.apply( lambda row: os.path.join(row[\"source\"], row[\"partition\"], row[\"filename\"]), axis = 1)\n",
    "    \n",
    "    # Creates a folder for the CSV files if needed\n",
    "    csv_dir = os.path.join(\"..\", \"metadata\")\n",
    "    if not os.path.exists(csv_dir):\n",
    "        os.makedirs(csv_dir)\n",
    "    \n",
    "    # Saves the dataframe\n",
    "    dataset_csv_path = os.path.join( csv_dir, \"{}_data.csv\".format(dataset) )\n",
    "    source_df.to_csv( dataset_csv_path, index = False, sep = \";\" )\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f651cc47",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True CNCB\n",
      "True COVID-19-CT-Seg\n",
      "True COVID-CT-MD\n",
      "True COVID-CTset\n",
      "True LIDC-IDRI\n",
      "True STOIC\n",
      "True Stony Brook\n",
      "True TCIA\n",
      "True iCTCF\n",
      "True radiopaedia.org\n",
      "\n",
      "\n",
      "1/10 - radiopaedia.org:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3574/3574 [01:37<00:00, 36.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "2/10 - LIDC-IDRI:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3999/3999 [01:36<00:00, 41.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "3/10 - COVID-CTset:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12058/12058 [05:08<00:00, 39.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "4/10 - Stony Brook:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 14461/14461 [04:48<00:00, 50.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "5/10 - COVID-CT-MD:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 23280/23280 [07:43<00:00, 50.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "6/10 - iCTCF:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 45912/45912 [16:08<00:00, 47.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "7/10 - CNCB:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 115837/115837 [39:41<00:00, 48.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "8/10 - COVID-19-CT-Seg:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1726/1726 [00:34<00:00, 49.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "9/10 - TCIA:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11816/11816 [03:53<00:00, 50.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "10/10 - STOIC:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 192361/192361 [1:07:49<00:00, 47.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List of unique sources (datasets used to build COVIDx CT-3A)\n",
    "source_list = [ \"radiopaedia.org\", \"LIDC-IDRI\", \"COVID-CTset\", \"Stony Brook\", \n",
    "                \"COVID-CT-MD\", \"iCTCF\", \"CNCB\", \"COVID-19-CT-Seg\", \"TCIA\", \"STOIC\" ]\n",
    "\n",
    "for src in np.unique( samples_df[\"source\"].to_list() ):\n",
    "    print(src in source_list, src)\n",
    "print(\"\\n\")\n",
    "\n",
    "# sizes_list = [224, 240, 260, 299, 300, \"original\"]\n",
    "sizes_list = [240, 260]\n",
    "\n",
    "for idx, src in enumerate(source_list):\n",
    "    print( \"{}/{} - {}:\\n\".format(idx+1, len(source_list), src) )\n",
    "    resize_samples( samples_df, data_dir, \"3A_images\", export_dir, src, sizes_list )\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc4b30d",
   "metadata": {},
   "source": [
    "# Verify Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5a63222",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_paths( i_dir, data_source, sizes ):\n",
    "    \n",
    "    metadata_csv_path = os.path.join(i_dir, \"{}_data.csv\".format(data_source))\n",
    "    df = pd.read_csv(metadata_csv_path, sep = \";\", na_filter = False, dtype={\"age\": str})\n",
    "    \n",
    "    # List of all paths\n",
    "    path_list = df[\"path\"].to_list()\n",
    "\n",
    "    # List of paths per partition\n",
    "    train_path_list = df[df[\"partition\"] == \"train\"][\"path\"].to_list()\n",
    "    val_path_list   = df[df[\"partition\"] ==   \"val\"][\"path\"].to_list()\n",
    "    test_path_list  = df[df[\"partition\"] ==  \"test\"][\"path\"].to_list()\n",
    "\n",
    "    for p in tqdm(path_list):\n",
    "    \n",
    "        for size in sizes:\n",
    "\n",
    "            path = os.path.join( i_dir, f\"{size}x{size}\", p )\n",
    "\n",
    "            if not os.path.exists( path ):\n",
    "                print(\"\\n\\tPath '{}' does not exist...\".format(path))\n",
    "\n",
    "            num_partitions = np.sum([ (p in train_path_list), (p in val_path_list), (p in test_path_list) ])\n",
    "\n",
    "            if num_partitions > 1:\n",
    "                print(\"\\n\\tSample '{}' belongs to >1 partition...\".format(path))\n",
    "\n",
    "            if num_partitions < 1:\n",
    "                print(\"\\n\\tSample '{}' does not belong to any partition...\".format(path))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f59f912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/10 - radiopaedia.org:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3574/3574 [00:01<00:00, 2137.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "2/10 - LIDC-IDRI:\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Datasets\\\\COVID19\\\\CT\\\\classification\\\\LIDC-IDRI_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, dataset_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataset_list):\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m( \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(idx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(dataset_list), dataset_name) )\n\u001b[1;32m----> 8\u001b[0m     \u001b[43mcheck_paths\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mexport_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msizes_list\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36mcheck_paths\u001b[1;34m(i_dir, data_source, sizes)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_paths\u001b[39m( i_dir, data_source, sizes ):\n\u001b[0;32m      3\u001b[0m     metadata_csv_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(i_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(data_source))\n\u001b[1;32m----> 4\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetadata_csv_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m;\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_filter\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# List of all paths\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     path_list \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto_list()\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\federated_ct\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\federated_ct\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:586\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    571\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    572\u001b[0m     dialect,\n\u001b[0;32m    573\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    582\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    583\u001b[0m )\n\u001b[0;32m    584\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 586\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\federated_ct\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:482\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    479\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    481\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 482\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    484\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    485\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\federated_ct\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:811\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwds:\n\u001b[0;32m    809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 811\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\federated_ct\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1040\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1036\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1037\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown engine: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mengine\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (valid options are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmapping\u001b[38;5;241m.\u001b[39mkeys()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1038\u001b[0m     )\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;66;03m# error: Too many arguments for \"ParserBase\"\u001b[39;00m\n\u001b[1;32m-> 1040\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mapping[engine](\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions)\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\federated_ct\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:51\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     48\u001b[0m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musecols\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39musecols\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# open handles\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open_handles\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Have to pass int, would break tests using TextReader directly otherwise :(\u001b[39;00m\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\federated_ct\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py:222\u001b[0m, in \u001b[0;36mParserBase._open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_handles\u001b[39m(\u001b[38;5;28mself\u001b[39m, src: FilePathOrBuffer, kwds: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;124;03m    Let the readers open IOHandles after they are done with their potential raises.\u001b[39;00m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 222\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[43m        \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    230\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\federated_ct\\lib\\site-packages\\pandas\\io\\common.py:702\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    697\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    698\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    701\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 702\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    703\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    704\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    706\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    707\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    708\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    709\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    710\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    711\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Datasets\\\\COVID19\\\\CT\\\\classification\\\\LIDC-IDRI_data.csv'"
     ]
    }
   ],
   "source": [
    "dataset_list = list(source_list)\n",
    "\n",
    "# Relative path to dataset\n",
    "assert os.path.exists( export_dir ), \"Unable to find the relative path to resized images, please check image_dir...\"\n",
    "\n",
    "for idx, dataset_name in enumerate(dataset_list):\n",
    "    print( \"{}/{} - {}:\\n\".format(idx+1, len(dataset_list), dataset_name) )\n",
    "    check_paths( export_dir, dataset_name, sizes_list )\n",
    "    print(\"\\n\\n\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "213px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
